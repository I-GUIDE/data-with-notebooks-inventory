{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47f4e33-5c48-4422-99fc-ccae884b6d31",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Choropleth Maps - Data Classification and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ed936-f233-4154-86a6-2b7dd9861196",
   "metadata": {},
   "source": [
    "Author: Fangzheng Lyu\n",
    "\n",
    "This notebook is related to the paper [Mapping dynamic human sentiments of heat exposure with location-based social media data](https://www.tandfonline.com/doi/full/10.1080/13658816.2024.2343063)\n",
    "\n",
    "Evaulting and mapping human sentiments of heat exposure.\n",
    "- Natural Interval\n",
    "- Qantile Map\n",
    "- Equal Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e096aa-1394-47a8-a8f8-e20b53559baf",
   "metadata": {},
   "source": [
    "## Notebook Outline\n",
    "- [Processing Twitter/X Data](#processing)\n",
    "- [Understanding How Human Sentiments of Heat Exposure from Tweet Posts](#understand)\n",
    "- [Aggregate the result to the census tract](#aggregate)\n",
    "- [Choropleth Map](#map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4acfeff-e276-4f81-9444-769368d9808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Library\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import json\n",
    "from shapely.geometry import Polygon, Point, MultiPolygon\n",
    "import shapefile\n",
    "import re\n",
    "import shapefile as shp  # Requires the pyshp package\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d3878-e98a-4f12-882e-17f0b0f64765",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='processing'></a>\n",
    "\n",
    "## 1. Processing Twitter/X Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fba3dc-088b-4609-9571-7311f376c239",
   "metadata": {},
   "source": [
    "The following cell will allow users to extract and filter the social media data Twitter/X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5903c555-d0ad-49ff-b5aa-dcf715fff131",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load chicago shapefile\n",
    "shapefile = gpd.read_file(\"./geo/geo_export_5bb8636f-65b7-450a-8fd9-7f01027fd84b.shp\")\n",
    "chicago_shape = shapefile[\"geometry\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93e169-2624-4c2a-8214-9584208e8926",
   "metadata": {},
   "source": [
    "Filter all the Twitter/X data by location, find all data within the city of Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931ad1e-220b-48d3-a817-b68aaa215392",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the twitter in chicago\n",
    "## City scale analysis\n",
    "## This block of code will takes a long time\n",
    "## We iterate through all the twitter collected for find twitter in chicago\n",
    "## Get the filename\n",
    "filelist = os.listdir('./data/')\n",
    "filelist\n",
    "\n",
    "twitter_in_chicago = []\n",
    "\n",
    "# Opening JSON file\n",
    "for filename in filelist:\n",
    "    filepath = \"./data/\"+filename\n",
    "    print(filepath)\n",
    "    f = open(filepath)\n",
    "    data = json.load(f)\n",
    "    \n",
    "    ## Read the data if the centroid of the twitter point polygon lies within the boundary of the city of Chicago\n",
    "    for i in range(0, len(data)):\n",
    "        try:\n",
    "            ##Need to deal with case when the shapefile is too big\n",
    "            text = data[i][\"text\"]\n",
    "            t = data[i]['created_at']\n",
    "            ## Case 1\n",
    "            ## Twitter with exact geospatial location\n",
    "            if (data[i]['geo']!=None):\n",
    "                lat = data[i]['geo']['coordinates'][0]\n",
    "                lon = data[i]['geo']['coordinates'][1]\n",
    "                exact_loc = Point(lon, lat)\n",
    "                if chicago_shape.contains(exact_loc):\n",
    "                    ## print(\"inside\")\n",
    "                    twitter_in_chicago.append((exact_loc, t, text))\n",
    "            else:\n",
    "                ## Twitter with a polygon bounding box\n",
    "                poly = data[i]['place']['bounding_box'][\"coordinates\"][0]\n",
    "                lon = -1000\n",
    "                lat = -1000\n",
    "\n",
    "                lon = [p[0] for p in poly]\n",
    "                lat = [p[1] for p in poly]\n",
    "                centroid = (sum(lon) / len(poly), sum(lat) / len(poly))\n",
    "                point = Point(centroid)\n",
    "                ## check if a centroid is in the bounding box of chicago\n",
    "                if chicago_shape.contains(point):\n",
    "                    ## print(\"inside\")\n",
    "                    twitter_in_chicago.append((poly, t, text))\n",
    "        except:\n",
    "            ## no geographical location\n",
    "            pass\n",
    "    # Closing file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490834e3-2bcf-47a3-a883-cfc0bfa53edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"There are in total \"+str(len(twitter_in_chicago))+\" geo-tagged Twitter Collected in Chicago in 9/25/2021 & 9/26/2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b8f3b-aa58-4933-8317-662b91a78d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of Twitter Message\n",
    "twitter_in_chicago[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156859e8-7ba0-4f2a-986f-66f9c8d2f699",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='understand'></a>\n",
    "\n",
    "## 2. Understanding How Human Sentiments of Heat Exposure from Tweet Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c11b7f-c49f-4010-b7e2-47db97373488",
   "metadata": {},
   "source": [
    "The following cell will allow users to apply heat dictionary generated using pretrained NLP model to understand the Twitter post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cba125-aef3-4e32-8bfc-8f8765df1092",
   "metadata": {},
   "source": [
    "A keyword-based NLP mehtod is adopted to the generated the heat dictionary. And the heat dictionary is used to access whether each Tweet post is talking about weather and how much is it talking about hot/cold weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d030f-c961-47a1-88a0-5c745f40193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the word heat dictionary\n",
    "f = open('./geo/data20000.txt','r')\n",
    "content = f.read()\n",
    "f.close()\n",
    "dict_word = {}\n",
    "content_list = content.split(\",\")\n",
    "for i in range(0,len(content_list)):\n",
    "    try:\n",
    "        word = content_list[i].split(\":\")[0].split(\"'\")[1]\n",
    "        #print(content_list[i].split(\":\"))\n",
    "        val = float(content_list[i].split(\":\")[1])\n",
    "        dict_word[word] = val\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1872d47-6b0f-4e82-815a-7c5d0be3a685",
   "metadata": {},
   "source": [
    "Apply the heat dictionary onto all the Tweets found in the city of Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654dc18-cbe7-4a5f-9138-1d57ae91e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterate through all twitter data in chicago\n",
    "\n",
    "d_twitter = []\n",
    "for i in range(0, len(twitter_in_chicago)):\n",
    "    loc = twitter_in_chicago[i][0]\n",
    "    t = twitter_in_chicago[i][1]\n",
    "    text = twitter_in_chicago[i][2]\n",
    "    res = re.findall(r'\\w+', text.lower())\n",
    "    val = 0\n",
    "    for word in res:\n",
    "        if word in dict_word.keys():\n",
    "            val = val + dict_word[word]\n",
    "    ## remove weather-irrelevant twitter\n",
    "    ## if none of the word in the heat dictionary show up \n",
    "    if (val!=0):\n",
    "        d_twitter.append((loc, t, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb82714-d3c1-4f8b-8fde-1924b2df4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \"+str(len(d_twitter))+\" weather-related Twitter in Chicago\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e76c5-d521-4588-9b67-5bf49f129a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dic = {}\n",
    "m_dic['Jan'] = 1\n",
    "m_dic['Feb'] = 2\n",
    "m_dic['Mar'] = 3\n",
    "m_dic['Apr'] = 4\n",
    "m_dic['May'] = 5\n",
    "m_dic['Jun'] = 6\n",
    "m_dic['Jul'] = 7\n",
    "m_dic['Aug'] = 8\n",
    "m_dic['Sep'] = 9\n",
    "m_dic['Oct'] = 10\n",
    "m_dic['Nov'] = 11\n",
    "m_dic['Dec'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3b4d2-aa31-4850-a840-13d8b29b7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the time difference between the current time and the Twitter post time\n",
    "today = datetime(2021,9, 25, 0)\n",
    "weather_related_twitter = []\n",
    "sec = []\n",
    "for twitter in d_twitter:\n",
    "    loc = twitter[0]\n",
    "    t = twitter[1].split()\n",
    "    val = twitter[2]\n",
    "    month = m_dic[t[1]]\n",
    "    day = int(t[2])\n",
    "    year = int(t[5])\n",
    "    hour = int(t[3].split(\":\")[0])\n",
    "    minute = int(t[3].split(\":\")[1])\n",
    "    twitter_t = datetime(year, month, day, hour, minute)\n",
    "    diff_minute = abs(twitter_t - today).total_seconds() / 60.0\n",
    "    weather_related_twitter.append((loc, diff_minute, val))\n",
    "    sec.append(diff_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb016e1-c85f-45dd-8751-0019197708e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the temporal distributed with weather-related Tweets posted across time\n",
    "\n",
    "plt.hist(sec, bins=100, alpha=0.5)\n",
    "plt.title('When the tweets are posted')\n",
    "plt.xlabel('Minute')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293be04f-0e87-4ce8-b330-3e679a155c48",
   "metadata": {},
   "source": [
    "<a id='aggregate'></a>\n",
    "\n",
    "## 3. Aggregate the result to the census tract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bebbc5-273b-4fe5-91e2-c01bd453b3ef",
   "metadata": {},
   "source": [
    "The following cell will allow users to aggregate the human sentiments of heat exposure from each Tweets to the spaital domain in the city of Chicago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac6eded-284c-4a29-817d-ab35b26d5e06",
   "metadata": {},
   "source": [
    "Aggregate the result into census tract. [Inverse Distance Weighting (IDW)](https://en.wikipedia.org/wiki/Inverse_distance_weighting) is used when a census tract value is missinng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdcdbe6-888a-4acc-81f7-1c670d97ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Integrate into census tract level\n",
    "chicago = gpd.read_file(\"./Census_tract/geo_export_dc0b9c70-c036-4bcc-a602-8e9b9d36ea9f.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf67a2f-1ce0-4bd6-9498-620515938c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5db8d-f609-4b6a-9c96-2dac73fb7a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a random point from a polygon\n",
    "import random\n",
    "\n",
    "def generate_random(number, polygon):\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    pnt = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "    return pnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7011174f-8602-4cd1-8a1d-b0b502cef22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to generate random location twitter\n",
    "## For monte caro experiment\n",
    "## Enable exact and poly if you want to see how many twitter has exact location and how many comes with a polygon\n",
    "#exact = 0\n",
    "#poly = 0\n",
    "def generate_random_loc(weather_related_twitter):\n",
    "    random_loc_twitter = []\n",
    "    for ele in weather_related_twitter:\n",
    "        loc = ele[0]\n",
    "        point = 0\n",
    "        #print(loc)\n",
    "        if (type(loc)==Point):\n",
    "            ## exact location extracted\n",
    "            point = loc\n",
    "            #exact = exact+1\n",
    "        else:\n",
    "            ## Select a random point from a multi-polygon\n",
    "            point = generate_random(1, Polygon(loc))\n",
    "            #poly = poly+1\n",
    "        random_loc_twitter.append([point, ele[2]])\n",
    "    return random_loc_twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81b90d-8e01-486c-9b7c-72ff824a7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_final_census_track = {}\n",
    "\n",
    "for i in range(0, 10):\n",
    "    ## try 10 random time\n",
    "    print(\"current \"+str(i))\n",
    "\n",
    "    ## Conduct kernel density estimation\n",
    "    random_loc_twitter = generate_random_loc(weather_related_twitter)\n",
    "\n",
    "    ### fill with inverse distance weighting\n",
    "\n",
    "\n",
    "    for index, row in chicago.iterrows():\n",
    "        key = index\n",
    "        ele = row['geometry'] \n",
    "        lon = ele.centroid.x\n",
    "        lat = ele.centroid.y\n",
    "        ## iterate through all the values in the existing twitter\n",
    "        up = 0\n",
    "        down = 0\n",
    "        IDW = 0\n",
    "        for twitter in random_loc_twitter:\n",
    "            pt = twitter[0]\n",
    "            curr_x = pt.x\n",
    "            curr_y = pt.y\n",
    "            curr_val = twitter[1]\n",
    "\n",
    "            distx = (curr_x-lon)*82\n",
    "            disty = (curr_y-lat)*111\n",
    "\n",
    "            w = 1/np.sqrt(distx*distx+disty*disty)\n",
    "\n",
    "            down = down+w\n",
    "            up = up+w*curr_val\n",
    "        rt = up/down\n",
    "\n",
    "        if (key not in d_final_census_track.keys()):\n",
    "            d_final_census_track[index]=[rt]\n",
    "        else:\n",
    "            d_final_census_track[index].append(rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f7dc2-da3b-4744-b9ee-b573c4370fc3",
   "metadata": {},
   "source": [
    "Calculate Normalized Human Sentiments of Heat Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868fb81-5cc4-4c6b-b251-7ae946757819",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_exposure_map_census_track = {}\n",
    "for key in d_final_census_track.keys():\n",
    "    ## Get the average hot exposure\n",
    "    heat_exposure_map_census_track[key] = np.mean(d_final_census_track[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda581f9-8356-406b-b2bd-06ad9c66af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nomalization to 0-1\n",
    "mn = min(heat_exposure_map_census_track.values())\n",
    "mx = max(heat_exposure_map_census_track.values())\n",
    "for key in heat_exposure_map_census_track.keys():\n",
    "    norm = (heat_exposure_map_census_track[key]-mn)/(mx-mn)\n",
    "    heat_exposure_map_census_track[key] = norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a168d90-c2dc-4cbe-96c0-c916bec614d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago[\"he_val\"]=list(heat_exposure_map_census_track.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ee5281-d544-41c1-ac61-00054759f005",
   "metadata": {},
   "source": [
    "Show the result geopandas dataframe for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40dd206-c213-4fe2-aa04-40307b679072",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89315cf5-33ff-49e5-9440-b7fa734b8e2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='map'></a>\n",
    "\n",
    "## 4. Choropleth Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b829958-f5ac-48a7-845f-ecbf7b44aa23",
   "metadata": {},
   "source": [
    "The following cell will introduce Choropleth Map and show users with different methods for data classificaiton, including quantile, equal interval, and natural break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ef9d9-14cd-4f58-a099-4d939ae066b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at how the heat exposure variable is distributed with a histogram\n",
    "chicago[\"he_val\"].hist(bins=40)\n",
    "plt.xlabel(\"Normalized Heat Exposure\")\n",
    "plt.ylabel(\"Number of census tracts\")\n",
    "plt.title(\"Human Centiments of Heat Exposure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3e672-7e0f-4ff3-bb15-1172e441f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Choropleth Map with geopandas \n",
    "chicago.plot(column = 'he_val', #Assign numerical data column\n",
    "                      legend = True, #Decide to show legend or not\n",
    "                      figsize = [20,10],\n",
    "                      cmap = 'YlOrRd',\n",
    "                      legend_kwds = {'label': \"Normalized Heat Exposure\"}) #Name the legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b3365-b323-4663-bd46-73d596f9d547",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Quantile Classification\n",
    "Quantile classification is a method in GIS for dividing numerical data into classes with an equal number of values in each class. It is useful for creating choropleth maps that visually represent the distribution of data across geographic areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f5f73-7739-4921-ba73-7eb77b47e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_val= list(chicago['he_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b731a41-2f14-4a01-94c2-c1fa9847926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show the percentile value for 5 classes\n",
    "\n",
    "print(\"The 20th percentile is \" + str(np.percentile(he_val, 20)))\n",
    "print(\"The 40th percentile is \" + str(np.percentile(he_val, 40)))\n",
    "print(\"The 60th percentile is \" + str(np.percentile(he_val, 60)))\n",
    "print(\"The 80th percentile is \" + str(np.percentile(he_val, 80)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74303cd7-26aa-4535-ade0-bd548192f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quantile Map\n",
    "chicago.plot(column = 'he_val', #Assign numerical data column\n",
    "                      scheme=\"quantiles\", \n",
    "                      k=5,\n",
    "                      legend = True, #Decide to show legend or not\n",
    "                      figsize = [20,10],\n",
    "                      cmap = 'YlOrRd') #Name the legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9ef6b1-03b1-47d5-a549-3de25c4b647a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Equal Interval Classification\n",
    "Equal interval classification is a method used in GIS to divide a range of numerical data into classes or intervals of equal size. In this method, the total range of the data (the difference between the maximum and minimum values) is divided into a specified number of equal-sized intervals or classes, with each class having the same width or size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8118307-5c99-4d74-9afb-9ddb53391dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_val= list(chicago['he_val'])\n",
    "mn, mx = min(he_val), max(he_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc642932-4224-4410-be6c-ccec5188b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn,mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189eb6f2-afa7-47ba-93cb-438285e457b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show the equal interval value for 5 class\n",
    "\n",
    "print(\"The 1th value is \" + str(1*(mx-mn)/5))\n",
    "print(\"The 2nd value is \" + str(2*(mx-mn)/5))\n",
    "print(\"The 3rd value is \" + str(3*(mx-mn)/5))\n",
    "print(\"The 4th value is \" + str(4*(mx-mn)/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a393a5-3824-44ca-9bc4-8b45b20ce744",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Equal Interval\n",
    "chicago.plot(column = 'he_val', #Assign numerical data column\n",
    "                      scheme=\"equal_interval\", \n",
    "                      k=5,\n",
    "                      legend = True, #Decide to show legend or not\n",
    "                      figsize = [20,10],\n",
    "                      cmap = 'YlOrRd') #Name the legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ebe36a-1df3-4d80-9b01-7abaf11e43c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Natural Break\n",
    "\n",
    "Jenks natural breaks is a data classification method in GIS that determines the best arrangement of values into different classes by minimizing the variance within classes and maximizing the variance between classes. It aims to reveal natural groupings and patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e5fc9-d1d8-4ae5-8143-f260138e9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jenkspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8cfd59-f372-4944-8e48-07a7b4aabedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jenkspy\n",
    "he_val= list(chicago['he_val'])\n",
    "\n",
    "[a0, a1, a2, a3, a4, a5] = jenkspy.jenks_breaks(he_val, n_classes=5)\n",
    "print(\"The 1th value is \" + str(a1))\n",
    "print(\"The 2nd value is \" + str(a2))\n",
    "print(\"The 3rd value is \" + str(a3))\n",
    "print(\"The 4th value is \" + str(a4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7faea-d8d5-4414-9d81-52e49d81c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Natural Break\n",
    "chicago.plot(column = 'he_val', #Assign numerical data column\n",
    "                      scheme=\"natural_breaks\", \n",
    "                      k=5,\n",
    "                      legend = True, #Decide to show legend or not\n",
    "                      figsize = [20,10],\n",
    "                      cmap = 'YlOrRd') #Name the legend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
